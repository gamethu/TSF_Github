# Best model estimator
import itertools
from matplotlib import pyplot as plt
import numpy as np
from sklearn.model_selection import GridSearchCV, RepeatedKFold, learning_curve, validation_curve
import pandas as pd

def FindBestTuningModel(model, param_grid, train_X, train_y):
    cv = RepeatedKFold(
        n_splits  = 10,
        n_repeats = 10,
        random_state = 40020409
    )
    grid_cv = GridSearchCV(
        estimator = model,
        param_grid = param_grid,
        scoring = "accuracy",
        n_jobs = 5, # Import, as high as value ~ as much as precessore in order to run
        cv = cv,
        refit = True
    )
    grid_cv.fit(train_X,train_y)
    print(f"{type(model).__name__}'s best parameters: {grid_cv.best_params_}")

    cv_results   = pd.DataFrame(grid_cv.cv_results_).filter(like = "split")
    best_results = cv_results.loc[grid_cv.best_index_, :]

    print(f"Mean accuracy          : {best_results.mean()}")
    print(f"Accuracy std deviation : {best_results.std()}")

    return grid_cv.best_estimator_

# Model tuning
def plot_VC(X_data, Y_data, model, param_grid, n_jobs, ylim=None, log=True):
    for param_name, param_range in param_grid.items():
        train_scores, test_scores = validation_curve(
            model, X_data, Y_data,
            param_name  = param_name,
            param_range = param_range,
            scoring     = "accuracy",
            n_jobs      = n_jobs
        )

        train_scores_mean = np.mean(train_scores, axis=1)
        train_scores_std  = np.std(train_scores, axis=1)
        test_scores_mean  = np.mean(test_scores, axis=1)
        test_scores_std   = np.std(test_scores, axis=1)

        # plt.figure(figsize=(8, 5))
        plt.title(f"Validation Curve for {param_name}")

        if ylim is not None:
            plt.ylim(*ylim)

        best_index       = np.argmax(test_scores_mean)
        best_param_value = param_range[best_index]
        best_score       = test_scores_mean[best_index]

        # ðŸ‘‰ Váº½ Ä‘Æ°á»ng tháº³ng xanh nÃ©t Ä‘á»©t trÆ°á»›c tiÃªn
        plt.axvline(x=best_param_value, color='b', linestyle='--', label=f"Best Score = {best_score:.2f}")

        plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
        plt.fill_between(param_range, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")

        if log:
            plt.semilogx(param_range, train_scores_mean, 'o-', color="r", label="Training score")
            plt.semilogx(param_range, test_scores_mean, 'o-', color="g", label="Test score")
        else:
            plt.plot(param_range, train_scores_mean, 'o-', color="r", label="Training score")
            plt.plot(param_range, test_scores_mean, 'o-', color="g", label="Test score")

        y_text = best_score + 0.02 if ylim is None else min(best_score + 0.02, ylim[1] - 0.01)
        plt.text(best_param_value, y_text, f" Score: {best_score:.4f}\n {param_name}: {best_param_value}", 
                 color='b', fontsize=9, ha='left')

        plt.xlabel(f'Parameter: {param_name}')
        plt.ylabel('Score')
        plt.legend(loc="lower right")
        plt.grid()
        # plt.tight_layout()
        plt.show()

        # In káº¿t quáº£ ra ngoÃ i terminal Ä‘á»ƒ tiá»‡n copy-paste
        print(f"Validation Curve for {param_name}:")
        print(f"  â†’ Best {param_name} = {best_param_value}")
        print(f"  â†’ Best CV Score     = {best_score:.4f}\n")
def plot_LC(X_data, Y_data, model, train_sizes, random_state, n_jobs):
    # plt.figure(figsize=(8, 5))
    plt.title("Learning Curve")
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.grid()

    train_sizes, train_scores, test_scores = learning_curve(
        model, X_data, Y_data, n_jobs=n_jobs, train_sizes=train_sizes, random_state=random_state
    )

    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std  = np.std(train_scores, axis=1)
    test_scores_mean  = np.mean(test_scores, axis=1)
    test_scores_std   = np.std(test_scores, axis=1)

    # === TÃ¬m vá»‹ trÃ­ cÃ³ test score cao nháº¥t
    best_index = np.argmax(test_scores_mean)
    best_train_size = train_sizes[best_index]
    best_score = test_scores_mean[best_index]

    # TÃ­nh tá»‰ lá»‡ train size Ä‘Ã³ trÃªn tá»•ng dá»¯ liá»‡u
    best_train_ratio = best_train_size / len(X_data)

    # Váº½ Ä‘Æ°á»ng tháº³ng nÃ©t Ä‘á»©t táº¡i Ä‘iá»ƒm Ä‘Ã³ (váº½ trÆ°á»›c Ä‘á»ƒ khÃ´ng Ä‘Ã¨ lÃªn line)
    plt.axvline(x=best_train_size, color='b', linestyle='--', label=f"Best CV Score = {best_score:.2f}")

    # Váº½ vÃ¹ng sai sá»‘
    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
    plt.fill_between(train_sizes, test_scores_mean  - test_scores_std,  test_scores_mean  + test_scores_std,  alpha=0.1, color="g")

    # Váº½ Ä‘Æ°á»ng train vÃ  test score
    plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_scores_mean,  'o-', color="g", label="Test score")

    # ChÃº thÃ­ch giÃ¡ trá»‹ Ä‘iá»ƒm sá»‘ vÃ  train size táº¡i vá»‹ trÃ­ Ä‘Ã³
    plt.text(best_train_size + (train_sizes.max() * 0.02), best_score,
             f"Score: {best_score:.4f}\nTrain size: {int(best_train_size)}\nRatio: {best_train_ratio:.4f}",
             color='b', fontsize=9, ha='left')

    plt.legend(loc="best")
    # plt.tight_layout()
    plt.show()

    # In káº¿t quáº£ ra ngoÃ i terminal Ä‘á»ƒ tiá»‡n copy-paste
    print("Learning Curve Results:")
    print(f"  â†’ Best train size   = {best_train_size} samples")
    print(f"  â†’ Ratio             = {best_train_ratio:.4f}")
    print(f"  â†’ Best CV Score     = {best_score:.4f}\n")
def plot_LC_multi_models(X_datasets, Y_data, models, model_names, train_sizes, random_state, n_jobs):
    plt.figure(figsize=(12, 7))
    plt.title("Learning Curves for Multiple Models")
    plt.xlabel("Training examples")
    plt.ylabel("Score")
    plt.grid()

    # Danh sÃ¡ch mÃ u khÃ¡c nhau
    colors = itertools.cycle(['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 
                              'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'])

    # LÆ°u trung bÃ¬nh test score cá»§a tá»«ng model Ä‘á»ƒ tÃ­nh vá»‹ trÃ­ tá»‘t nháº¥t
    all_test_scores_mean = []

    for X_data, model, name in zip(X_datasets, models, model_names):
        color = next(colors)

        train_sizes_res, train_scores, test_scores = learning_curve(
            model, X_data, Y_data, n_jobs=n_jobs, train_sizes=train_sizes, random_state=random_state
        )

        train_scores_mean = np.mean(train_scores, axis=1)
        train_scores_std  = np.std(train_scores, axis=1)
        test_scores_mean  = np.mean(test_scores, axis=1)
        test_scores_std   = np.std(test_scores, axis=1)

        all_test_scores_mean.append(test_scores_mean)

        # ÄÆ°á»ng train score - nÃ©t liá»n
        plt.plot(train_sizes_res, train_scores_mean, 'o-', color=color, label=f"{name} Train Score")
        plt.fill_between(train_sizes_res,
                         train_scores_mean - train_scores_std,
                         train_scores_mean + train_scores_std,
                         alpha=0.1, color=color)

        # ÄÆ°á»ng CV score - nÃ©t Ä‘á»©t
        plt.plot(train_sizes_res, test_scores_mean, 'o--', color=color, label=f"{name} CV Score")
        plt.fill_between(train_sizes_res,
                         test_scores_mean - test_scores_std,
                         test_scores_mean + test_scores_std,
                         alpha=0.1, color=color)

    # TÃ­nh trung bÃ¬nh test score táº¥t cáº£ models
    avg_test_scores = np.mean(all_test_scores_mean, axis=0)

    # TÃ¬m train size tá»‘t nháº¥t
    best_index = np.argmax(avg_test_scores)
    best_train_size = train_sizes_res[best_index]
    best_score = avg_test_scores[best_index]

    # TÃ­nh tá»· lá»‡ train_size / max_train_size
    train_size_ratio = best_train_size / max(train_sizes_res)

    # Váº½ Ä‘Æ°á»ng tháº³ng táº¡i train size tá»‘t nháº¥t
    plt.axvline(x=best_train_size, color='blue', linestyle='--', linewidth=1.5,
                label=f"Best avg CV Score = {best_score:.2f} at {best_train_size} ({train_size_ratio:.2%})")

    plt.legend(loc="best")
    plt.tight_layout()
    plt.show()

    print(f"\n=> Best average CV Score = {best_score:.4f} at train size = {best_train_size} ({train_size_ratio:.4f})")