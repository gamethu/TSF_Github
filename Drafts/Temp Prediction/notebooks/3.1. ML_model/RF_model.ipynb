{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:orange\">1.Introduction<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">1.1. Project purpose</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this competition (both train and test) was generated from a deep learning model trained on the UCI Mushroom dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n",
    "\n",
    "Note: Unlike many previous Tabular Playground datasets, data artifacts have not been cleaned up. There are categorical values in the dataset that are not found in the original. It is up to the competitors how to handle this.\n",
    "\n",
    "Files\n",
    "* train.csv - the training dataset; class is the binary target (either e or p)\n",
    "* test.csv - the test dataset; your objective is to predict target class for each row\n",
    "* sample_submission.csv - a sample submission file in the correct format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">1.2. Data source and description</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_type = dict({\n",
    "    'class'                : ['e', 'p'],\n",
    "    'cap-diameter'         : 'Numerical',\n",
    "    'cap-shape'            : ['b', 'c', 'x', 'f', 'k', 's'],\n",
    "    'cap-surface'          : ['f', 'g', 'y', 's'],\n",
    "    'cap-color'            : ['n', 'b', 'c', 'g', 'r', 'p', 'u', 'e', 'w', 'y'],\n",
    "    'does-bruise-or-bleed' : ['f', 't'],\n",
    "    'gill-attachment'      : ['a', 'f', 'd', 'n'],\n",
    "    'gill-spacing'         : ['c', 'w', 'd'],\n",
    "    'gill-color'           : ['k', 'n', 'b', 'h', 'g', 'r', 'o', 'p', 'u', 'e', 'w', 'y'],\n",
    "    'stem-height'          : 'Numerical',\n",
    "    'stem-width'           : 'Numerical',\n",
    "    'stem-root'            : ['b', 'c', 'u', 'e', 'z', 'r', '?'],\n",
    "    'stem-surface'         : ['f', 'y', 'k', 's'],\n",
    "    'stem-color'           : ['n', 'b', 'c', 'g', 'o', 'p', 'e', 'w', 'y'],\n",
    "    'veil-type'            : ['p', 'u'],\n",
    "    'veil-color'           : ['n', 'o', 'w', 'y'],\n",
    "    'has-ring'             : ['f', 't'],\n",
    "    'ring-type'            : ['c', 'l', 'e', 'n', 'f', 'p', 's', 'z'],\n",
    "    'spore-print-color'    : ['k', 'n', 'b', 'h', 'r', 'o', 'u', 'w', 'y'],\n",
    "    'habitat'              : ['g', 'l', 'm', 'p', 'u', 'w', 'd'],\n",
    "    'season'               : ['a', 'u', 'w', 's']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/playground-series-s4e8/data\n",
    "- Train_data: Dùng file “train.csv” (train/train.csv)\n",
    "- Test_data: Dùng file “test.csv” (test/test.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">1.3. Goals</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accuracy as much as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">2.Import Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">2.1. Required Python packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder  # Encode feature\n",
    "from sklearn.preprocessing import OrdinalEncoder # Encode feature\n",
    "from sklearn.preprocessing import MinMaxScaler   # Scale feature\n",
    "from sklearn.preprocessing import StandardScaler # Scale feature\n",
    "from sklearn.preprocessing import LabelEncoder   # Encode target\n",
    "# from scipy.stats import boxcox # Normalized feature\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif # PCA\n",
    "from sklearn.model_selection   import train_test_split\n",
    "from sklearn.model_selection   import RepeatedKFold\n",
    "from sklearn.model_selection   import GridSearchCV\n",
    "from sklearn.model_selection   import validation_curve\n",
    "from sklearn.model_selection   import learning_curve\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes  import MultinomialNB\n",
    "from sklearn.naive_bayes  import BernoulliNB\n",
    "from sklearn.naive_bayes  import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.neighbors    import KNeighborsClassifier\n",
    "from sklearn.svm          import SVC\n",
    "from xgboost              import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">2.2. Configuration and display settings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../scripts\")\n",
    "\n",
    "import script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">3.Data Loading</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">3.1. Loading the dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/train_cleaned.csv\", index_col = \"id\")\n",
    "test_df  = pd.read_csv(\"../../data/test_cleaned.csv\" , index_col = \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">3.2. Displaying first few rows</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">3.3. Data summary</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">7.Feature ~ Target</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">7.1. Feature Selection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.drop(columns=[\"class\"],axis=1)\n",
    "targets  = train_df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aproach1\n",
    "le = LabelEncoder()\n",
    "targets_encoded = le.fit_transform(targets)\n",
    "\n",
    "\n",
    "# # Aproach2\n",
    "# targets_encoded = targets_encoded.replace({'e': 0, 'p': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">7.2. Dimensionality Reducing</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">PCA</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_scores = script.make_mi_scores(\n",
    "    X_data = features, \n",
    "    y_data = targets\n",
    ")\n",
    "\n",
    "print(mi_scores.head(20))\n",
    "# print(mi_scores.head(20))\n",
    "# print(mi_scores.tail(20))  # uncomment to see bottom 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.plot_mi_scores(mi_scores)\n",
    "# script.plot_mi_scores(mi_scores.head(62))\n",
    "# script.plot_mi_scores(mi_scores.tail(38))  # uncomment to see bottom 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lấy số lượng cột cần giữ lại (17 số cột có điểm MI cao nhất)\n",
    "num_columns_to_keep = 17\n",
    "\n",
    "# Lấy danh sách các cột cần giữ lại\n",
    "columns_to_keep = mi_scores.nlargest(num_columns_to_keep).index\n",
    "\n",
    "# Cập nhật X_train_encoded và X_test_encoded chỉ với các cột được giữ lại\n",
    "features = features[columns_to_keep]\n",
    "\n",
    "# Hiển thị các cột còn lại\n",
    "print(f\"Các cột được giữ lại:\\n{features.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">7.3. Feature Engineering</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = features.select_dtypes(exclude='number').columns\n",
    "categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feature = features.select_dtypes(include='number').columns\n",
    "numerical_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Encode categorical feature</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[categorical_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [match_type[col] for col in categorical_feature]\n",
    "# encoder = OrdinalEncoder(\n",
    "#     categories = categories,\n",
    "#     handle_unknown = 'use_encoded_value', \n",
    "#     unknown_value  = -1\n",
    "# )\n",
    "encoder = OneHotEncoder(\n",
    "    categories = categories,\n",
    "    sparse_output  = False,\n",
    "    handle_unknown = \"ignore\"\n",
    ")\n",
    "\n",
    "features_encoded  = deepcopy(features)\n",
    "\n",
    "# # Encode\n",
    "features_cat_encoded  = encoder.fit_transform(features[categorical_feature])\n",
    "\n",
    "# Kiểm tra số cột\n",
    "print(\"Số cột của dữ liệu đã mã hóa: \", features_cat_encoded.shape[1])\n",
    "\n",
    "# Loại bỏ các cột trong `categorical` khỏi features_encoded\n",
    "features_encoded  = features_encoded.drop(columns=categorical_feature)\n",
    "\n",
    "# Thêm các cột đã mã hóa vào features_encoded\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_feature)\n",
    "\n",
    "# Tạo DataFrame từ các cột đã mã hóa và gán lại tên cột\n",
    "features_encoded  = pd.DataFrame(features_cat_encoded, columns=encoded_columns, index=features.index)\n",
    "\n",
    "# Kết hợp lại với các cột còn lại trong features_encoded\n",
    "features_encoded  = pd.concat([features_encoded, features.drop(columns=categorical_feature)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">7.4. Feature Scaling</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded[numerical_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data = features_encoded[numerical_feature],\n",
    "    kde = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "features_scale = scaler.fit_transform(features_encoded[numerical_feature])\n",
    "\n",
    "features_encoded[numerical_feature] = features_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded[numerical_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    data = features_encoded[numerical_feature],\n",
    "    kde = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">7.5. Save data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index thành cột 'id'\n",
    "features_encoded = features_encoded.reset_index().rename(columns={'index': 'id'})\n",
    "\n",
    "# Chuyển target thành DataFrame\n",
    "targets_df = pd.DataFrame(targets_encoded, columns=['class'])\n",
    "\n",
    "# Ghép ngang\n",
    "merged_df = pd.concat([features_encoded, targets_df], axis=1)\n",
    "\n",
    "# Xuất CSV\n",
    "merged_df.to_csv('GNB_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">8.Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded = pd.read_csv(\"GNB_encoded.csv\", index_col = \"id\")\n",
    "targets_encoded  = features_encoded[\"class\"]\n",
    "features_encoded = features_encoded.drop(columns = [\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">8.1. Building models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Building Models ~ aproach1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_nb_model = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Building Models ~ aproach2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    # \"alpha\": np.logspace(-3, 1, 20),         # Multinomial, Bernoulli\n",
    "    \"var_smoothing\": np.logspace(-10, 10, 20) # Gaussian\n",
    "}\n",
    "\n",
    "script.plot_VC(\n",
    "    X_data     = features_encoded,\n",
    "    Y_data     = targets_encoded,\n",
    "    model      = GaussianNB(),\n",
    "    param_grid = param_grid,\n",
    "    ylim       = [0.01,1.20],\n",
    "    n_jobs     = 4 # Quan trong: value o day quyet dinh se su dung bao nhieu processor de chay ~> cang cao cang tot\n",
    ") # 0.9689 ~ 0.002335721469090121 ~ np.logspace(-10, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nb_model = GaussianNB(\n",
    "    var_smoothing = 0.002335721469090121\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "joblib.dump(best_nb_model, 'GNB_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Building Models ~ aproach3</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     # \"alpha\": np.logspace(-3, 1, 20),         # Multinomial, Bernoulli\n",
    "#     \"var_smoothing\": np.logspace(-9, -5, 10) # Gaussian\n",
    "# }\n",
    "\n",
    "# best_nb_model = script.FindBestTuningModel(\n",
    "#     model      = GaussianNB(),\n",
    "#     param_grid = param_grid,\n",
    "#     train_X    = features_encoded,\n",
    "#     train_y    = targets_encoded\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">8.2. Training models</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Training Models ~ aproach1</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(features_encoded, targets_encoded, test_size = 0.2, random_state=40024090)\n",
    "# best_nb_model.fit(X_train_encoded, y_train_encoded)\n",
    "# y_pred = best_nb_model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Training Models ~ aproach2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.plot_LC(\n",
    "    X_data       = features_encoded,\n",
    "    Y_data       = targets_encoded,\n",
    "    model        = best_nb_model,\n",
    "    train_sizes  = np.linspace(0.2, 1, 20),\n",
    "    random_state = 40020409,\n",
    "    n_jobs       = 4 # Quan trong: value o day quyet dinh se su dung bao nhieu processor de chay ~> cang cao cang tot\n",
    ") # 0.9693 ~ 0.4968 ~ np.linspace(0.2, 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(\n",
    "    features_encoded, targets_encoded, \n",
    "    train_size   = 0.4968,\n",
    "    random_state = 40020409\n",
    ")\n",
    "best_nb_model.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred = best_nb_model.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">8.3. Save models</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lưu model\n",
    "joblib.dump(best_nb_model, 'GNB_model_trained.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">9.Model Evaluation</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">9.1. Load model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lại model\n",
    "best_nb_model = joblib.load('GNB_model_trained.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">9.2. Evaluation Metrics</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_test_encoded, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs   = accuracy_score(y_test_encoded, y_pred)\n",
    "\n",
    "print(f\"Accuracy Score : {acs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the train-set and test-set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_nb_model.predict(X_train_encoded)\n",
    "y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs   = accuracy_score(y_train_encoded, y_pred_train)\n",
    "print(f\"R² Score : {acs:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set score : {:.4f}'.format(best_nb_model.score(X_train_encoded, y_train_encoded)))\n",
    "print('Test set score     : {:.4f}'.format(best_nb_model.score(X_test_encoded, y_test_encoded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">9.3. Visualizing Evaluation results</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">ROC Curve</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = best_nb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "nb_auc = roc_auc_score(y_test_encoded, y_pred1)\n",
    "nb_fpr, nb_tpr, _ = roc_curve(y_test_encoded, y_pred1)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 8))\n",
    "plt.plot(nb_fpr, nb_tpr,   label='Naive Bayes (AUC = %0.4f)' % nb_auc)\n",
    "plt.plot([0, 1], [0, 1],   label='Random Guess       (AUC=0.500)')\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Confusion matrix</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
    "\n",
    "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
    "\n",
    "True Positives (TP) – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
    "\n",
    "True Negatives (TN) – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
    "\n",
    "False Positives (FP) – False Positives occur when we predict an observation belongs to a certain class but the observation actually does not belong to that class. This type of error is called Type I error.\n",
    "\n",
    "False Negatives (FN) – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called Type II error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.plot_CF_aproach1(y_test_encoded, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.plot_CF_aproach2(y_test_encoded, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Classification metrices</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report\n",
    "\n",
    "Classification report is another way to evaluate the classification model performance. It displays the precision, recall, f1 and support scores for the model. I have described these terms in later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_encoded, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:tomato\">Class probabilities</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = best_nb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# Vẽ histogram + kde\n",
    "sns_hist = sns.histplot(\n",
    "    y_pred1, \n",
    "    bins=10, \n",
    "    kde=True, \n",
    "    edgecolor='black', \n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Lấy các thông tin cần từ histogram\n",
    "counts, edges = np.histogram(y_pred1, bins=10)\n",
    "total = len(y_pred1)\n",
    "\n",
    "# Thêm số phần trăm lên từng cột\n",
    "for i in range(len(counts)):\n",
    "    bin_center = (edges[i] + edges[i+1]) / 2\n",
    "    height = counts[i]\n",
    "    plt.text(bin_center, height + height*0.01, \n",
    "             f'{(counts[i]/total*100):.1f}%', \n",
    "             ha='center', fontsize=9)\n",
    "\n",
    "plt.title('Histogram of predicted probabilities with KDE')\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Predicted probability (class=1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\">9.4. Interpretation of performance</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "# lr_param_grid = {\n",
    "#     'C': np.logspace(-4, 4, 10),    # regularization strength\n",
    "#     'solver': ['lbfgs', 'liblinear']\n",
    "# }\n",
    "# best_lr_model = script.FindBestModel(\n",
    "#     LogisticRegression(max_iter=1000),\n",
    "#     lr_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "# # Decision Tree\n",
    "# dt_param_grid = {\n",
    "#     'max_depth': [3, 5, 7, 10, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "# best_dt_model = script.FindBestModel(\n",
    "#     DecisionTreeClassifier(random_state=42),\n",
    "#     dt_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "# # Random Forest\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'max_features': ['sqrt', 'log2', 5],\n",
    "#     'max_depth': [None, 5, 10],\n",
    "#     'min_samples_split': [2, 5, 10]\n",
    "# }\n",
    "# best_rf_model = script.FindBestModel(\n",
    "#     RandomForestClassifier(random_state=42),\n",
    "#     rf_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "# KNN\n",
    "# knn_param_grid = {\n",
    "#     'n_neighbors': [3, 5, 7, 9, 11],\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "# }\n",
    "# best_knn_model = script.FindBestTuningModel(\n",
    "#     KNeighborsClassifier(),\n",
    "#     knn_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "# # SVM\n",
    "# svm_param_grid = {\n",
    "#     'C': np.logspace(-3, 3, 7),\n",
    "#     'kernel': ['linear', 'rbf'],\n",
    "#     'gamma': ['scale', 'auto']\n",
    "# }\n",
    "# best_svm_model = script.FindBestModel(\n",
    "#     SVC(probability=True, random_state=42),\n",
    "#     svm_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "# # XGBoost\n",
    "# xgb_param_grid = {\n",
    "#     'n_estimators': [100, 300, 500],\n",
    "#     'max_depth': [3, 5, 7],\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "# }\n",
    "# best_xgb_model = script.FindBestModel(\n",
    "#     XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "#     xgb_param_grid,\n",
    "#     X_train_encoded, y_train_encoded\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "best_lr_model = LogisticRegression(C=1.0, solver='lbfgs', max_iter=1000)\n",
    "best_lr_model.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Decision Tree\n",
    "best_dt_model = DecisionTreeClassifier(max_depth=5, min_samples_split=2, criterion='gini', random_state=42)\n",
    "best_dt_model.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Random Forest\n",
    "best_rf_model = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=5, min_samples_split=2, random_state=42)\n",
    "best_rf_model.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# KNN\n",
    "# best_knn_model = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n",
    "# best_knn_model.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# # SVM\n",
    "# best_svm_model = SVC(C=1.0, kernel='rbf', gamma='scale', probability=True, random_state=42)\n",
    "# best_svm_model.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# # XGBoost\n",
    "# best_xgb_model = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "# best_xgb_model.fit(X_train_encoded, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression : Training set score = {:.4f}'.format(best_lr_model.score(X_train_encoded, y_train_encoded)))\n",
    "print('                      Test set score     = {:.4f}'.format(best_lr_model.score(X_test_encoded, y_test_encoded)))\n",
    "\n",
    "print('Decision Tree        : Training set score = {:.4f}'.format(best_dt_model.score(X_train_encoded, y_train_encoded)))\n",
    "print('                      Test set score     = {:.4f}'.format(best_dt_model.score(X_test_encoded, y_test_encoded)))\n",
    "\n",
    "print('Random Forest        : Training set score = {:.4f}'.format(best_rf_model.score(X_train_encoded, y_train_encoded)))\n",
    "print('                      Test set score     = {:.4f}'.format(best_rf_model.score(X_test_encoded, y_test_encoded)))\n",
    "\n",
    "# print('K-Nearest Neighbors  : Training set score = {:.4f}'.format(best_knn_model.score(X_train_encoded, y_train_encoded)))\n",
    "# print('                      Test set score     = {:.4f}'.format(best_knn_model.score(X_test_encoded, y_test_encoded)))\n",
    "\n",
    "# print('Support Vector Machine : Training set score = {:.4f}'.format(best_svm_model.score(X_train_encoded, y_train_encoded)))\n",
    "# print('                        Test set score     = {:.4f}'.format(best_svm_model.score(X_test_encoded, y_test_encoded)))\n",
    "\n",
    "# print('XGBoost               : Training set score = {:.4f}'.format(best_xgb_model.score(X_train_encoded, y_train_encoded)))\n",
    "# print('                        Test set score     = {:.4f}'.format(best_xgb_model.score(X_test_encoded, y_test_encoded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_probs  = best_lr_model.predict_proba(X_test_encoded)[:, 1]\n",
    "dt_probs  = best_dt_model.predict_proba(X_test_encoded)[:, 1]\n",
    "rf_probs  = best_rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "# knn_probs = best_knn_model.predict_proba(X_test_encoded)[:, 1]\n",
    "# svm_probs = best_svm_model.predict_proba(X_test_encoded)[:, 1]\n",
    "# xgb_probs = best_xgb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "y_pred1 = best_nb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "nb_auc = roc_auc_score(y_test_encoded, y_pred1)\n",
    "lr_auc = roc_auc_score(y_test_encoded, lr_probs)\n",
    "dt_auc  = roc_auc_score(y_test_encoded, dt_probs)\n",
    "rf_auc = roc_auc_score(y_test_encoded, rf_probs)\n",
    "# knn_auc = roc_auc_score(y_test_encoded, knn_probs)\n",
    "# svm_auc = roc_auc_score(y_test_encoded, svm_probs)\n",
    "# xgb_auc = roc_auc_score(y_test_encoded, xgb_probs)\n",
    "print(f'Naive Bayes         : AUROC = {nb_auc:.3f}')\n",
    "print(f'Logistic Regression : AUROC = {lr_auc:.3f}')\n",
    "print(f'Decision Tree       : AUROC = {dt_auc:.3f}')\n",
    "print(f'Random Forest       : AUROC = {rf_auc:.3f}')\n",
    "# print(f'K-Nearest Neighbors : AUROC = {knn_auc:.3f}')\n",
    "# print(f'SVM                 : AUROC = {svm_auc:.3f}')\n",
    "# print(f'XGBoost             : AUROC = {xgb_auc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fpr, nb_tpr, _ = roc_curve(y_test_encoded, y_pred1)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(y_test_encoded, lr_probs)\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test_encoded, dt_probs)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test_encoded, rf_probs)\n",
    "# fpr_knn, tpr_knn, _ = roc_curve(y_test_encoded, knn_probs)\n",
    "# fpr_svm, tpr_svm, _ = roc_curve(y_test_encoded, svm_probs)\n",
    "# fpr_xgb, tpr_xgb, _ = roc_curve(y_test_encoded, xgb_probs)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(nb_fpr, nb_tpr,   label='Naive Bayes        (AUC = %0.4f)' % nb_auc)\n",
    "plt.plot(lr_fpr, lr_tpr,   label='LogisticRegression (AUC = %0.4f)' % lr_auc)\n",
    "plt.plot(fpr_dt, tpr_dt,   label=f'Decision Tree     (AUC={dt_auc:.4f})')\n",
    "plt.plot(rf_fpr, rf_tpr,   label=f'Random Forest     (AUC = %0.4f)' % rf_auc)\n",
    "# plt.plot(fpr_knn, tpr_knn, label=f'KNN               (AUC={knn_auc:.4f})')\n",
    "# plt.plot(fpr_svm, tpr_svm, label=f'SVM               (AUC={svm_auc:.4f})')\n",
    "# plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost           (AUC={xgb_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1],   label='Random Guess       (AUC=0.500)')\n",
    "\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = best_rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# Vẽ histogram + kde\n",
    "sns_hist = sns.histplot(\n",
    "    y_pred1, \n",
    "    bins=10, \n",
    "    kde=True, \n",
    "    edgecolor='black', \n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Lấy các thông tin cần từ histogram\n",
    "counts, edges = np.histogram(y_pred1, bins=10)\n",
    "total = len(y_pred1)\n",
    "\n",
    "# Thêm số phần trăm lên từng cột\n",
    "for i in range(len(counts)):\n",
    "    bin_center = (edges[i] + edges[i+1]) / 2\n",
    "    height = counts[i]\n",
    "    plt.text(bin_center, height + height*0.01, \n",
    "             f'{(counts[i]/total*100):.1f}%', \n",
    "             ha='center', fontsize=9)\n",
    "\n",
    "plt.title('Histogram of predicted probabilities with KDE')\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Predicted probability (class=1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:orange\">10. Conclusion</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deepcopy test_df cho tập validation\n",
    "X_val_encoded = deepcopy(test_df)\n",
    "\n",
    "# Sắp xếp đúng thứ tự cột gốc trước khi encode (có thể không cần nếu test_df đã đúng thứ tự)\n",
    "X_val_encoded = X_val_encoded[columns_to_keep]\n",
    "\n",
    "# Encode tập validation\n",
    "X_val_cat_encoded = encoder.transform(X_val_encoded[categorical_feature])\n",
    "\n",
    "# Tạo DataFrame mới từ cột mã hóa\n",
    "encoded_columns = encoder.get_feature_names_out(categorical_feature)\n",
    "X_val_cat_encoded_df = pd.DataFrame(X_val_cat_encoded, columns=encoded_columns, index=X_val_encoded.index)\n",
    "\n",
    "# Loại bỏ cột categorical khỏi X_val_encoded\n",
    "X_val_encoded = X_val_encoded.drop(columns=categorical_feature)\n",
    "\n",
    "# Nối lại cột encode vào\n",
    "X_val_encoded = pd.concat([X_val_encoded, X_val_cat_encoded_df], axis=1)\n",
    "\n",
    "# Sắp xếp lại thứ tự cột theo đúng feature_encoded\n",
    "X_val_encoded = X_val_encoded[features_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X_val_encoded contains only the columns used during training\n",
    "# X_val_encoded = X_val_encoded[columns_to_keep]\n",
    "\n",
    "# Predict the target variable\n",
    "y_val_predict = best_nb_model.predict(X_val_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = best_nb_model.predict_proba(X_val_encoded)[:, 1]\n",
    "\n",
    "# Vẽ histogram + kde\n",
    "sns_hist = sns.histplot(\n",
    "    y_pred2, \n",
    "    bins=10, \n",
    "    kde=True, \n",
    "    edgecolor='black', \n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Lấy các thông tin cần từ histogram\n",
    "counts, edges = np.histogram(y_pred2, bins=10)\n",
    "total = len(y_pred2)\n",
    "\n",
    "# Thêm số phần trăm lên từng cột\n",
    "for i in range(len(counts)):\n",
    "    bin_center = (edges[i] + edges[i+1]) / 2\n",
    "    height = counts[i]\n",
    "    plt.text(bin_center, height + height*0.01, \n",
    "             f'{(counts[i]/total*100):.1f}%', \n",
    "             ha='center', fontsize=9)\n",
    "\n",
    "plt.title('Histogram of predicted probabilities with KDE')\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Predicted probability (class=1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
